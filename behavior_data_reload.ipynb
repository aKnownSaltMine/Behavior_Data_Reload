{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tableauhyperapi as tab\n",
    "import os\n",
    "import win32com.client\n",
    "from shutil import rmtree, move\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "import pyodbc\n",
    "from tqdm import tqdm\n",
    "import sqlalchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tableau_url = '' # Network URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "data_folder = os.path.join(cwd, 'Data')\n",
    "dashboard_file = 'Behavior Analyzer Agent Performance IV VR.twbx'\n",
    "dasboard_path = os.path.join(data_folder, dashboard_file)\n",
    "\n",
    "hyper_folder = os.path.join(data_folder, 'hyper')\n",
    "if os.path.exists(hyper_folder) == False:\n",
    "    os.makedirs(hyper_folder)\n",
    "else:\n",
    "    rmtree(hyper_folder)\n",
    "    os.makedirs(hyper_folder)\n",
    "\n",
    "\n",
    "download_folder = os.path.join(Path.home(), 'Downloads')\n",
    "download_path = os.path.join(download_folder, dashboard_file)\n",
    "\n",
    "while os.path.exists(download_path) == False:\n",
    "    print(f'Dashboard has not been detected.')\n",
    "    print(f'Please download the report from: {tableau_url}')\n",
    "    print('-'*25)\n",
    "    input('Press Enter when completed')\n",
    "else:\n",
    "    print('Dashboard detected. Continuing with the script.')\n",
    "    move(download_path, dasboard_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tableau File Extracted\n"
     ]
    }
   ],
   "source": [
    "with ZipFile(dasboard_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(hyper_folder)\n",
    "    print(\"Tableau File Extracted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_folder = os.path.join(hyper_folder, 'Data', 'Extracts')\n",
    "database_folder_contents = os.listdir(database_folder)\n",
    "hyper_files = [value for value in database_folder_contents if value.endswith('.hyper')]\n",
    "\n",
    "if len(hyper_files) > 1:\n",
    "    print('there is more than one hyper file')\n",
    "\n",
    "database_path = os.path.join(database_folder, hyper_files[0])\n",
    "print(database_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tab.HyperProcess(telemetry=tab.Telemetry.DO_NOT_SEND_USAGE_DATA_TO_TABLEAU) as hyper:\n",
    "    with tab.Connection(hyper.endpoint, database=database_path) as connection:\n",
    "        table_name = tab.TableName(\"Extract\", \"Extract\")\n",
    "        table_definition = connection.catalog.get_table_definition(name=table_name)\n",
    "        column_names = [str(value.name)[1:-1] for value in table_definition.columns]\n",
    "        results = connection.execute_list_query(query=f\"SELECT agent_id, behavior, caldt, deno_mediafilecount, num_mediafilecount FROM {table_name} WHERE lob = 'Video Repair'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows extracted: 651,273\n"
     ]
    }
   ],
   "source": [
    "column_names = ['Agent Id','Behavior','Caldt','Denominator Count','Numerator Count']\n",
    "df = pd.DataFrame(data=results, columns=column_names)\n",
    "df = df.dropna(how='all', subset=['Denominator Count','Numerator Count']).reset_index(drop=True)\n",
    "df['Caldt'] = df['Caldt'].astype(str)\n",
    "df['Caldt'] = pd.to_datetime(df['Caldt']).dt.date\n",
    "row_count = df.shape[0]\n",
    "\n",
    "print(f'Total rows extracted: {row_count:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = df['Caldt'].min()\n",
    "earliest_date_str = earliest_date.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "clean_table_query = f'''\n",
    "DELETE FROM GVPOperations.VID.OAI_VR_Export where Caldt >= '{earliest_date.strftime(\"%m/%d/%Y\")}'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-07\n"
     ]
    }
   ],
   "source": [
    "print(f'Earliest date from Tableau: {earliest_date.strftime(\"%m/%d/%Y\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_name = '' # Network Server Name\n",
    "db_name = 'GVPOperations'\n",
    "\n",
    "engine = sqlalchemy.create_engine(f'mssql+pyodbc://@{server_name}/{db_name}?trusted_connection=yes&driver=ODBC+Driver+13+for+SQL+Server', fast_executemany=True)\n",
    "conn = engine.connect()\n",
    "print('Database connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import event\n",
    "@event.listens_for(engine, \"before_cursor_execute\")\n",
    "def receive_before_cursor_execute(\n",
    "       conn, cursor, statement, params, context, executemany\n",
    "        ):\n",
    "            if executemany:\n",
    "                cursor.fast_executemany = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old Rows Deleted\n"
     ]
    }
   ],
   "source": [
    "conn.execute(sqlalchemy.sql.text(clean_table_query))\n",
    "conn.commit()\n",
    "\n",
    "print('Old Rows Deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Writing {row_count:,} to database')\n",
    "df.to_sql(name='OAI_VR_Export', con=engine, schema='VID', if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
